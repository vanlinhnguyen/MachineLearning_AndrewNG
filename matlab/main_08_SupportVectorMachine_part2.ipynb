{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Support Vector Machines - Spam Classification\n",
    "\n",
    "This Matlab code has been completed as part of [Machine Learning](https://www.coursera.org/learn/machine-learning)\n",
    "course in Coursera given by Prof. Andrew Ng\n",
    "\n",
    "------------\n",
    "This note demonstrates the use of SVM for spam classification.\n",
    "\n",
    "Many email services today provide spam filters that are able to classify emails into spam and non-spam email with high accuracy. This note demonstrates the use of SVMs to build a spam filter. We will be training a classifier to classify whether a given email, x, is spam (y = 1) or non-spam (y = 0). To do so, we will need to convert each email into a feature vector $x \\in R^n$ for training a SVM classifier. \n",
    "\n",
    "This notebook includes:\n",
    "\n",
    "- <a href='#part1'>Part 1: Email Preprocessing</a>\n",
    "- <a href='#part2'>Part 2: Part 2: Train Linear SVM for Spam Classificationn</a>\n",
    "\n",
    "This code requires the following functions\n",
    "* <a href='#funcs_08_SupportVectorMachine_readFile.m'>funcs_08_SupportVectorMachine_readFile.m</a> \n",
    "* <a href='#funcs_08_SupportVectorMachine_processEmail.m'>funcs_08_SupportVectorMachine_processEmail.m</a>\n",
    "* <a href='#funcs_08_SupportVectorMachine_porterStemmer.m'>funcs_08_SupportVectorMachine_porterStemmer.m</a>\n",
    "* <a href='#funcs_08_SupportVectorMachine_svmTrain.m'>funcs_08_SupportVectorMachine_svmTrain.m</a>\n",
    "* <a href='#funcs_08_SupportVectorMachine_svmPredict.m'>funcs_08_SupportVectorMachine_svmPredict.m</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clear all; close all; clc; warning off;\n",
    "addpath('./data/') % add path to directory containing data files\n",
    "addpath('./funcs/') % add path to directory containing subfunction files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Email Preprocessing <a id='part1'></a>\n",
    "\n",
    "Before starting on a machine learning task, it is usually insightful to take a look at examples from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "> Anyone knows how much it costs to host a web portal ?\n",
       ">\n",
       "Well, it depends on how many visitors you're expecting.\n",
       "This can be anywhere from less than 10 bucks a month to a couple of $100. \n",
       "You should checkout http://www.rackspace.com/ or perhaps Amazon EC2 \n",
       "if youre running something big..\n",
       "\n",
       "To unsubscribe yourself from this mailing list, send an email to:\n",
       "groupname-unsubscribe@egroups.com"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'data_08_SuportVectorMachine_part2_emailSample1.txt';\n",
    "file_contents = funcs_08_SupportVectorMachine_readFile(filename);\n",
    "fprintf('%s ', file_contents);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The sample email contains a URL, an email address (at the end), numbers, and dollar amounts. While many emails would contain similar types of entities (e.g., numbers, other URLs, or other email addresses), the specific entities (e.g., the specific URL or specific dollar amount) will be different in almost every\n",
    "email. Therefore, one method often employed in processing emails is to \"normalize\" these values, so that all URLs are treated the same, all numbers are treated the same, etc. For example, we could replace each URL in the email with the unique string \"httpaddr\" to indicate that a URL was present. This has the effect of letting the spam classifier make a classification decision based on whether any URL was present, rather than whether a specific URL\n",
    "was present. This typically improves the performance of a spam classifier, since spammers often randomize the URLs, and thus the odds of seeing any particular URL again in a new piece of spam is very small.\n",
    "\n",
    "In processEmail.m, we have implemented the following email preprocessing and normalization steps:\n",
    "* **Lower-casing:** The entire email is converted into lower case, so that captialization is ignored (e.g., IndIcaTE is treated the same as Indicate).\n",
    "* **Stripping HTML:** All HTML tags are removed from the emails. Many emails often come with HTML formatting; we remove all the HTML tags, so that only the content remains.\n",
    "* **Normalizing URLs:** All URLs are replaced with the text *\"httpaddr\"*.\n",
    "* **Normalizing Email Addresses:** with the text *\"emailaddr\"*.\n",
    "* **Normalizing Numbers:** All email addresses are replaced All numbers are replaced with the text *\"number\"*.\n",
    "* **Normalizing Dollars:** All dollar signs ($) are replaced with the text *\"dollar\"*.\n",
    "* **Word Stemming:** Words are reduced to their stemmed form. For example, *\"discount\"*, *\"discounts\"*, *\"discounted\"* and *\"discounting\"* are all replaced with *\"discount\"*. Sometimes, the Stemmer actually strips off additional characters from the end, so *\"include\"*, *\"includes\"*, *\"included\"*, and *\"including\"* are all replaced with *\"includ\"*. \n",
    "* **Removal of non-words:** Non-words and punctuation have been removed. All white spaces (tabs, newlines, spaces) have all been trimmed to a single space character.\n",
    "\n",
    "The result of these preprocessing steps is shown in Figure 9. While pre-processing has left word fragments and non-words, this form turns out to be much easier to work with for performing feature extraction.\n",
    "\n",
    "#### Vocabulary List:\n",
    "After preprocessing the emails, we have a list of words for each email. The next step is to choose which words we would like to use in our classifier and which we would want to leave out. For this test, we have chosen only the most frequently occuring words as our set of words considered (the vocabulary list). Since words that occur\n",
    "rarely in the training set are only in a few emails, they might cause the model to overfit our training set. The complete vocabulary list is in the file *vocab.txt*. This vocabulary list was selected by choosing all words which occur at least a 100 times in the spam corpus, resulting in a list of 1899 words. In practice, a vocabulary list with about 10,000 to 50,000 words is often used. \n",
    "\n",
    "Given the vocabulary list, we can now map each word in the preprocessed emails (e.g., Figure 9) into a list of word indices that contains the index of the word in the vocabulary list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "% Load Vocabulary\n",
    "fid = fopen('data_08_SuportVectorMachine_part2_vocab.txt');\n",
    "\n",
    "% Store all dictionary words in cell array vocab{}\n",
    "n = 1899;  % Total number of words in the dictionary\n",
    "\n",
    "% For ease of implementation, we use a struct to map the strings => integers\n",
    "% In practice, you'll want to use some form of hashmap\n",
    "vocabList = cell(n, 1);\n",
    "for i = 1:n\n",
    "    % Word Index (can ignore since it will be = i)\n",
    "    fscanf(fid, '%d', 1);\n",
    "    % Actual Word\n",
    "    vocabList{i} = fscanf(fid, '%s', 1);\n",
    "end\n",
    "fclose(fid);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==== Processed Email ====\n",
       "\n",
       "anyon know how much it cost to host a web portal well it depend on how mani \n",
       "visitor you re expect thi can be anywher from less than number buck a month \n",
       "to a coupl of dollarnumb you should checkout httpaddr or perhap amazon ecnumb \n",
       "if your run someth big to unsubscrib yourself from thi mail list send an \n",
       "email to emailaddr \n",
       "\n",
       "=========================\n",
       "Word Indices: \n",
       " 86 916 794 1077 883 370 1699 790 1822 1831 883 431 1171 794 1002 1893 1364 592 1676 238 162 89 688 945 1663 1120 1062 1699 375 1162 479 1893 1510 799 1182 1237 810 1895 1440 1547 181 1699 1758 1896 688 1676 992 961 1477 71 530 1699 531"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "% postprocess email\n",
    "word_indices  = funcs_08_SupportVectorMachine_processEmail(file_contents,vocabList);\n",
    "\n",
    "% Print Stats\n",
    "fprintf('Word Indices: \\n');\n",
    "fprintf(' %d', word_indices);\n",
    "fprintf('\\n\\n');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Features from Emails\n",
    "\n",
    "Now, you will convert each email into a vector of features in $R^n$. We will be using $n = \\# words$ in vocabulary\n",
    "list. Specifically, the feature $x_i \\in \\{0, 1\\}$ for an email corresponds to whether the $i^{th}$ word in the dictionary occurs in the email. That is, $x_i = 1$ if the $i^{th}$ word is in the email and $x_i = 0$ if the $i^{th}$ word is not present in the email. For a typical email, this feature would look like\n",
    "\n",
    "$$x=[0 \\: 0 \\: 1 \\: ... \\: 1 \\: 0 \\: ... \\: 0]^T \\in R^n$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Length of feature vector: 1899\n",
       "Number of non-zero entries: 45"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = zeros(n, 1);\n",
    "features(word_indices)=1;\n",
    "% Print Stats\n",
    "fprintf('Length of feature vector: %d\\n', length(features));\n",
    "fprintf('Number of non-zero entries: %d\\n', sum(features > 0));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Train Linear SVM for Spam Classification   <a id='part2'></a>\n",
    "\n",
    "After you have completed the feature extraction functions, the next step is to load a preprocessed training dataset that will be used to train a SVM classifier. The file *data_08_SuportVectorMachine_part2_spamTrain.mat* contains 4000 training examples of spam and non-spam email, while *data_08_SuportVectorMachine_part2_spamTest* contains 1000 test examples. Each original email was processed and converted into a vector $x^{(i)} \\in R^{1899}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Training Accuracy: 99.800000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load('./data/data_08_SuportVectorMachine_part2_spamTrain.mat');\n",
    "\n",
    "C = 0.1;\n",
    "svm_model = funcs_08_SupportVectorMachine_svmTrain(X, y, C, @linearKernel);\n",
    "\n",
    "pred_train = funcs_08_SupportVectorMachine_svmPredict(svm_model, X);\n",
    "fprintf('Training Accuracy: %f\\n', mean(double(pred_train == y)) * 100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Testing Accuracy: 98.700000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load('./data/data_08_SuportVectorMachine_part2_spamTest.mat');\n",
    "pred_test = funcs_08_SupportVectorMachine_svmPredict(svm_model, Xtest);\n",
    "fprintf('Testing Accuracy: %f\\n', mean(double(pred_test == ytest)) * 100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top Predictors for Spam\n",
    "To better understand how the spam classifier works, we can inspect the parameters to see which words the classifier thinks are the most predictive of spam. We finds the parameters with the largest positive values in the classifier. For example, if an email contains words such as \"guarante\", \"remove\", \"dollar\", and \"price\" (the top predictors), it is likely to be classified as spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Top predictors of spam: \n",
       " our             (0.500005) \n",
       " click           (0.466328) \n",
       " remov           (0.424416) \n",
       " guarante        (0.386305) \n",
       " visit           (0.368418) \n",
       " basenumb        (0.347584) \n",
       " dollar          (0.331071) \n",
       " will            (0.269945) \n",
       " price           (0.263403) \n",
       " pleas           (0.260972) \n",
       " lo              (0.260926) \n",
       " nbsp            (0.257982) \n",
       " most            (0.252809) \n",
       " ga              (0.248242) \n",
       " hour            (0.241250)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[weight, idx] = sort(svm_model.w, 'descend');\n",
    "\n",
    "fprintf('\\nTop predictors of spam: \\n');\n",
    "for i = 1:15\n",
    "    fprintf(' %-15s (%f) \\n', vocabList{idx(i)}, weight(i));\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try sample emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==== Processed Email ====\n",
       "\n",
       "do you want to make dollarnumb or more per week if you ar a motiv and qualifi \n",
       "individu i will person demonstr to you a system that will make you dollarnumb \n",
       "number per week or more thi is not mlm call our number hour pre record number \n",
       "to get the detail number number number i need peopl who want to make seriou \n",
       "monei make the call and get the fact invest number minut in yourself now \n",
       "number number number look forward to your call and i will introduc you to \n",
       "peopl like yourself who ar current make dollarnumb number plu per week number \n",
       "number number numberljgvnumb numberleannumberlrmsnumb \n",
       "numberwxhonumberqiytnumb numberrjuvnumberhqcfnumb numbereidbnumberdmtvlnumb \n",
       "\n",
       "=========================\n",
       "\n",
       "Processed ./data/data_08_SuportVectorMachine_part2_spamSample1.txt\n",
       "\n",
       "Spam Classification: 1\n",
       "(1 indicates spam, 0 indicates not spam)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = './data/data_08_SuportVectorMachine_part2_spamSample1.txt';\n",
    "file_contents = funcs_08_SupportVectorMachine_readFile(filename);\n",
    "word_indices  = funcs_08_SupportVectorMachine_processEmail(file_contents,vocabList);\n",
    "x = zeros(n, 1);\n",
    "x(word_indices)=1;\n",
    "\n",
    "p = funcs_08_SupportVectorMachine_svmPredict(svm_model, x);\n",
    "\n",
    "fprintf('\\nProcessed %s\\n\\nSpam Classification: %d\\n', filename, p);\n",
    "fprintf('(1 indicates spam, 0 indicates not spam)\\n\\n');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==== Processed Email ====\n",
       "\n",
       "best bui viagra gener onlin viagra numbermg x number pill dollarnumb free \n",
       "pill reorder discount top sell number qualiti satisfact guarante we accept \n",
       "visa master e check payment number satisfi custom httpaddr \n",
       "\n",
       "=========================\n",
       "\n",
       "Processed ./data/data_08_SuportVectorMachine_part2_spamSample2.txt\n",
       "\n",
       "Spam Classification: 1\n",
       "(1 indicates spam, 0 indicates not spam)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = './data/data_08_SuportVectorMachine_part2_spamSample2.txt';\n",
    "file_contents = funcs_08_SupportVectorMachine_readFile(filename);\n",
    "word_indices  = funcs_08_SupportVectorMachine_processEmail(file_contents,vocabList);\n",
    "x = zeros(n, 1);\n",
    "x(word_indices)=1;\n",
    "\n",
    "p = funcs_08_SupportVectorMachine_svmPredict(svm_model, x);\n",
    "\n",
    "fprintf('\\nProcessed %s\\n\\nSpam Classification: %d\\n', filename, p);\n",
    "fprintf('(1 indicates spam, 0 indicates not spam)\\n\\n');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Todo list:\n",
    "\n",
    "* Build a dataset of training and testing set using the original emails from the SpamAssassin Public Corpus: Download the original files from the public corpus and extract them. After extracting, processing and extracting features from each email to extract a feature vector from each email. This will allow you to build a\n",
    "dataset X, y of examples. You should then randomly divide up the dataset into a training set, a cross validation set and a test set. While you are building your own dataset, we also encourage you to try building your own vocabulary list (by selecting the high frequency words \n",
    "\n",
    "The original emails will have email headers that you might wish to leave out. We have included code in processEmail that will help you remove these headers and adding any additional features that you think might be useful. \n",
    "\n",
    "* Finally, we also suggest trying to use highly optimized SVM toolboxes such as LIBSVM"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Matlab",
   "language": "matlab",
   "name": "matlab_kernel"
  },
  "language_info": {
   "codemirror_mode": "Octave",
   "file_extension": ".m",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://github.com/calysto/metakernel/blob/master/metakernel/magics/README.md"
    }
   ],
   "mimetype": "text/x-matlab",
   "name": "octave"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
